Dataset

Dataset rows : 15,596,924
Dataset columns: : 15
Dataset size : 8.2 GB 



Data Lake

1. Installation steps: https://itslinuxfoss.com/install-minio-ubuntu-22-04/
2. Start minIO server: sudo ./minio server /minio
3. Create user "dalas" with password "devdeav5"
4. Set alias: ./mc alias set myminio_dalas http://192.168.0.13:9000 dalas devdeav5
5. create bucket: ./mc mb myminio_dalas/hudi
6. Checking my spark version

      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 3.3.0
      /_/
         
Using Scala version 2.12.15 (OpenJDK 64-Bit Server VM, Java 11.0.17)


7. Downloading proper spark-hudi jar: wget  -P $SPARK_HOME/jars/ "https://repo1.maven.org/maven2/org/apache/hudi/hudi-spark3-bundle_2.12/0.12.2/hudi-spark3-bundle_2.12-0.12.2.jar"

8. Downloading proper aws java sdk bundle: wget -P $SPARK_HOME/jars/ "https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.398/aws-java-sdk-bundle-1.12.398.jar"

9. Downloading proper hadoop aws jar: wget -P $SPARK_HOME/jars/ "https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar"


10. Starting spark session with MinIO for storage

$SPARK_HOME/bin/spark-shell \
--jars 'hudi-spark3-bundle_2.12-0.12.2.jar,hadoop-aws-3.3.4.jar,aws-java-sdk-bundle-1.12.398.jar' \
--conf 'spark.serializer=org.apache.spark.serializer.KryoSerializer' \
--conf 'spark.sql.catalog.spark_catalog=org.apache.spark.sql.hudi.catalog.HoodieCatalog' \
--conf 'spark.sql.extensions=org.apache.spark.sql.hudi.HoodieSparkSessionExtension' \
--conf 'spark.hadoop.fs.s3a.access.key=dalas' \
--conf 'spark.hadoop.fs.s3a.secret.key=devdeav5' \
--conf 'spark.hadoop.fs.s3a.endpoint=http://192.168.0.13:9000' \
--conf 'spark.hadoop.fs.s3a.path.style.access=true' \
--conf 'spark.hadoop.fs.s3a.signing-algorithm=S3SignerType'



- Building Fat JAR: $sbt assembly  , on sbt project root folder

- spark-cluster location: /home/dalas/Documents/BigDataTrainee/RockTheJVM/spark-optimization/spark-cluster

- Copying fat jar file to cluster mount 
cp /home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar /home/dalas/Documents/BigDataTrainee/RockTheJVM/spark-optimization/spark-cluster/apps/data-lake-etl.jar


* Starting up cluster (cd to spark-cluster folder) : docker compose up --scale spark-worker=3
* logging to cluster-master: 			     docker exec -it spark-cluster-spark-master-1 bash

* executing spark-submit command for VALIDATION

* Spark cluster
$SPARK_HOME/bin/spark-submit --class com.dalas.DataLakeValidation --deploy-mode client --master spark://fc5dd8d02cc:7077 --verbose --supervise /opt/spark-apps/data-lake-etl.jar '/home/dalas/Downloads/archive' 's3a://amazon-data' 'amazon_reviews' '1998-07-15' '1999-12-31'

* Locally
1.

$SPARK_HOME/bin/spark-submit \
--class com.dalas.DataLakeValidation \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'1998-07-15' \
'1999-12-31'

2.

$SPARK_HOME/bin/spark-submit \
--class com.dalas.DataLakeValidation \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2000-01-01' \
'2002-12-31'


3.

$SPARK_HOME/bin/spark-submit \
--class com.dalas.DataLakeValidation \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2003-01-01' \
'2005-12-31'



4.

$SPARK_HOME/bin/spark-submit \
--class com.dalas.DataLakeValidation \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2006-01-01' \
'2008-12-31'

5.

$SPARK_HOME/bin/spark-submit \
--class com.dalas.DataLakeValidation \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2009-01-01' \
'2011-12-31'


6.

$SPARK_HOME/bin/spark-submit \
--driver-memory=10G \
--executor-memory=18G \
--class com.dalas.DataLakeValidation \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'1998-07-15' \
'2015-12-31'




* executing spark-submit command for HISTORY LOAD

1.

$SPARK_HOME/bin/spark-submit \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'1998-07-15' \
'1999-12-31'


2.

$SPARK_HOME/bin/spark-submit \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2000-01-01' \
'2002-12-31'

3.

$SPARK_HOME/bin/spark-submit \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2003-01-01' \
'2005-12-31'


4.

$SPARK_HOME/bin/spark-submit \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2006-01-01' \
'2006-12-31'



$SPARK_HOME/bin/spark-submit \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2007-01-01' \
'2007-12-31'


$SPARK_HOME/bin/spark-submit \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2008-01-01' \
'2008-12-31'





5.

$SPARK_HOME/bin/spark-submit \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2009-01-01' \
'2011-12-31'


$SPARK_HOME/bin/spark-submit \
--driver-memory=4G \
--executor-memory=16G \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2009-01-01' \
'2009-12-31'




$SPARK_HOME/bin/spark-submit \
--driver-memory=4G \
--executor-memory=16G \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2010-01-01' \
'2011-12-31'







6.

$SPARK_HOME/bin/spark-submit \
--driver-memory=4G \
--executor-memory=16G \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2012-01-01' \
'2015-12-31'



$SPARK_HOME/bin/spark-submit \
--driver-memory=4G \
--executor-memory=16G \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2012-01-01' \
'2012-12-31'


$SPARK_HOME/bin/spark-submit \
--driver-memory=10G \
--executor-memory=18G \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2013-01-01' \
'2013-12-31'


$SPARK_HOME/bin/spark-submit \
--driver-memory=10G \
--executor-memory=18G \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2014-01-01' \
'2014-12-31'



$SPARK_HOME/bin/spark-submit \
--driver-memory=10G \
--executor-memory=18G \
--class com.dalas.DataLakeETL \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
'/home/dalas/Downloads/archive' \
's3a://amazon-data' \
'amazon_reviews' \
'2015-01-01' \
'2015-12-31'





/* EDA command  */

$SPARK_HOME/bin/spark-submit \
--driver-memory=10G \
--executor-memory=18G \
--class com.dalas.AmazonEDA \
--master local[*] \
/home/dalas/Documents/master-tfm/data-lake-etl/target/scala-2.12/data-lake-etl-assembly-0.1.0-SNAPSHOT.jar \
's3a://amazon-data' \
's3a://amazon-eda' \
'amazon_reviews' \
'1998-07-15' \
'2015-12-31'




data-lake-etl properties
- sbt.version = 1.8.2
- scalaVersion := "2.12.15"
- 

/* Amazon NLP command */

$SPARK_HOME/bin/spark-submit \
--driver-memory=8G \
--executor-memory=16G \
--class com.dalas.AmazonNLP \
--master local[*] \
/home/dalas/Documents/master-tfm/amazon-nlp/target/scala-2.12/amazon-nlp-assembly-0.1.0-SNAPSHOT.jar \
's3a://amazon-data' \
's3a://amazon-ml/amazon-nlp' \
'amazon_reviews' \
'2010-01-01' \
'2015-12-31'



/* Amazon NLP Simple Test */


$SPARK_HOME/bin/spark-submit \
--driver-memory=6G \
--executor-memory=10G \
--class com.dalas.AmazonNLPSimpleTest \
--master local[*] \
/home/dalas/Documents/master-tfm/amazon-nlp/target/scala-2.12/amazon-nlp-assembly-0.1.0-SNAPSHOT.jar \
's3a://amazon-ml/amazon-nlp' \
'nlp-model.3.12' \
'nlp_pipeline.3.12'


Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
23/03/08 00:46:27 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.14 instead (on interface wlp0s20f3)
23/03/08 00:46:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/03/08 00:46:27 INFO SparkContext: Running Spark version 3.3.0
23/03/08 00:46:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/03/08 00:46:27 INFO ResourceUtils: ==============================================================
23/03/08 00:46:27 INFO ResourceUtils: No custom resources configured for spark.driver.
23/03/08 00:46:27 INFO ResourceUtils: ==============================================================
23/03/08 00:46:27 INFO SparkContext: Submitted application: Amazon NLP Model Simple Test
23/03/08 00:46:27 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/03/08 00:46:27 INFO ResourceProfile: Limiting resource is cpu
23/03/08 00:46:27 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/03/08 00:46:27 INFO SecurityManager: Changing view acls to: dalas
23/03/08 00:46:27 INFO SecurityManager: Changing modify acls to: dalas
23/03/08 00:46:27 INFO SecurityManager: Changing view acls groups to: 
23/03/08 00:46:27 INFO SecurityManager: Changing modify acls groups to: 
23/03/08 00:46:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dalas); groups with view permissions: Set(); users  with modify permissions: Set(dalas); groups with modify permissions: Set()
23/03/08 00:46:27 INFO Utils: Successfully started service 'sparkDriver' on port 39935.
23/03/08 00:46:27 INFO SparkEnv: Registering MapOutputTracker
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/dalas/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.3.0/spark-unsafe_2.12-3.3.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
23/03/08 00:46:27 INFO SparkEnv: Registering BlockManagerMaster
23/03/08 00:46:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/03/08 00:46:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/03/08 00:46:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/03/08 00:46:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a6aa0dfa-c3ed-4af0-bb27-4ba9893c67b0
23/03/08 00:46:27 INFO MemoryStore: MemoryStore started with capacity 4.5 GiB
23/03/08 00:46:27 INFO SparkEnv: Registering OutputCommitCoordinator
23/03/08 00:46:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/03/08 00:46:27 INFO Executor: Starting executor ID driver on host 192.168.0.14
23/03/08 00:46:27 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/03/08 00:46:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43891.
23/03/08 00:46:27 INFO NettyBlockTransferService: Server created on 192.168.0.14:43891
23/03/08 00:46:27 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/03/08 00:46:27 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.14, 43891, None)
23/03/08 00:46:27 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.14:43891 with 4.5 GiB RAM, BlockManagerId(driver, 192.168.0.14, 43891, None)
23/03/08 00:46:27 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.14, 43891, None)
23/03/08 00:46:27 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.14, 43891, None)
+--------------------------------------------------------+----------+
|review_body                                             |prediction|
+--------------------------------------------------------+----------+
|I'm totally disappointed, It broke the next day I used  |0.0       |
|I loved this product, it's great quality                |2.0       |
|It is ok for the price, but I don't recommend it        |2.0       |
|I hoped for more, but is acceptable quality, three stars|2.0       |
+--------------------------------------------------------+----------+





/*****          Collaborative Filtering Recommender **************** /


product_category = 'PC'

















